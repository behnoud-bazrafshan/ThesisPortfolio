{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "import os\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import jdatetime\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.linear_model import LinearRegression\n",
                "\n",
                "pd.options.mode.chained_assignment = None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# preparation (calculate MKB, SMB, and HML for estimating LIQ)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "----"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Calculate ME and BE, and write them to Excel files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check financial year for all tickers\n",
                "financial_years_list = []\n",
                "for file_number in range(1, 76):\n",
                "    path = f'E:/Thesis/New Sampling/Factor Model'\\\n",
                "        f'/Balance Sheet 2/{file_number}.xlsx'\n",
                "    df = pd.read_excel(path, skiprows=7, usecols=[1, *range(5, 15)])\n",
                "    financial_years_list.append(df.columns.tolist()[1:])\n",
                "pd.DataFrame(financial_years_list).to_excel('financial_years.xlsx')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract BE\n",
                "final_list = []\n",
                "for file_number in range(1, 76):\n",
                "    print(file_number)\n",
                "    path = f'E:/Thesis/New Sampling/Factor Model'\\\n",
                "        f'/Balance Sheet 2/{file_number}.xlsx'\n",
                "    df = pd.read_excel(path, skiprows=7, usecols=[1, *range(5, 15)])\n",
                "    condition = (df['دوره مالی'] == 'جمع حقوق صاحبان سهام')\n",
                "    be = df.loc[condition].values[0].tolist()[1:]\n",
                "    be = [i * 1000000 for i in be]\n",
                "    final_list.append(be)\n",
                "pd.DataFrame(final_list).to_excel('BE_raw_new.xlsx')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract ME\n",
                "# Read Bourseview data for market cap\n",
                "# Concat all 75 tickers' data\n",
                "me_list = []\n",
                "for file_number in range(1, 76):\n",
                "    me_path = f'E:/Thesis/New Sampling/Daily Data - Bourseview/'\\\n",
                "        f'{file_number}.xlsx'\n",
                "    me_df = pd.read_excel(\n",
                "        me_path,\n",
                "        skiprows=7,\n",
                "        usecols=[2, 3, 11],\n",
                "        names=['date', 'open', 'market_cap'],\n",
                "        na_values='-'\n",
                "    )\n",
                "    # Change order from old to new dates\n",
                "    me_df = me_df[::-1].reset_index(drop=True)\n",
                "    me_df['date'] = me_df['date'].str.replace('-', '')\n",
                "    # Delete non-traded days\n",
                "    me_df.dropna(subset=['open'], inplace=True)\n",
                "    me_df.drop(columns='open', inplace=True)\n",
                "    # Create monthly dataframe\n",
                "    me_df = me_df.groupby(me_df['date'].str[:4]).last()\n",
                "    me_df = me_df.drop(columns=['date']).reset_index()\n",
                "    me_df.insert(1, 'ticker_num', file_number)\n",
                "    me_list.append(me_df)\n",
                "me_df = pd.concat(me_list, ignore_index=True)\n",
                "me_df = me_df.loc[(me_df['date'] >= '1388') & (me_df['date'] <= '1397')]\n",
                "me_df = me_df.sort_values(['ticker_num', 'date'], ascending=[True, False])\n",
                "me_df.reset_index(drop=True, inplace=True)\n",
                "me_df = pd.pivot_table(\n",
                "    me_df,\n",
                "    values='market_cap',\n",
                "    index=['ticker_num'],\n",
                "    columns=['date']\n",
                ")\n",
                "me_df.columns.name = None\n",
                "me_df.rename(\n",
                "    columns={\n",
                "        '1388': '88',\n",
                "        '1389': '89',\n",
                "        '1390': '90',\n",
                "        '1391': '91',\n",
                "        '1392': '92',\n",
                "        '1393': '93',\n",
                "        '1394': '94',\n",
                "        '1395': '95',\n",
                "        '1396': '96',\n",
                "        '1397': '97'\n",
                "    },\n",
                "    inplace=True\n",
                ")\n",
                "me_df.reset_index(inplace=True)\n",
                "me_df = me_df[\n",
                "    ['ticker_num', '97', '96', '95', '94', '93', '92', '91', '90', '89', '88']\n",
                "]\n",
                "me_df.to_excel('ME_final.xlsx', index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Read ME and BM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read ME data\n",
                "me_path = r'C:\\Users\\behnood\\Desktop\\Thesis\\TSETMC\\Factor Model\\ME_final.xlsx'\n",
                "me_df = pd.read_excel(me_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read modified BM data\n",
                "bm_path = r'C:\\Users\\behnood\\Desktop\\Thesis\\TSETMC\\Factor Model\\BM_final.xlsx'\n",
                "bm_df = pd.read_excel(\n",
                "    bm_path,\n",
                "    usecols=[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
                "    names=[\n",
                "        'ticker_num', 'ticker', '97',\n",
                "        '96', '95', '94', '93', '92',\n",
                "        '91', '90', '89', '88'\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Calculate daily and monthly returns and market caps for SMB and HML Calculation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read Bourseview data for market cap\n",
                "# Concat all 75 tickers' data\n",
                "daily_bv_list = []\n",
                "monthly_bv_list = []\n",
                "for file_number in range(1, 76):\n",
                "    bv_path = f'E:/Thesis/New Sampling/Daily Data - Bourseview/'\\\n",
                "        f'{file_number}.xlsx'\n",
                "    bv_df = pd.read_excel(\n",
                "        bv_path,\n",
                "        skiprows=7,\n",
                "        usecols=[2, 3, 11, 14],\n",
                "        names=['date', 'open', 'market_cap', 'd_vol'],\n",
                "        na_values='-'\n",
                "    )\n",
                "    bv_df.insert(1, 'ticker_num', file_number)\n",
                "    # Change order from old to new dates\n",
                "    bv_df = bv_df[::-1].reset_index(drop=True)\n",
                "    bv_df['date'] = bv_df['date'].str.replace('-', '')\n",
                "    # Delete non-traded days\n",
                "    bv_df.dropna(subset=['open'], inplace=True)\n",
                "    bv_df.drop(columns='open', inplace=True)\n",
                "    daily_bv_list.append(bv_df)\n",
                "    # Create monthly dataframe\n",
                "    bv_df = bv_df.groupby(bv_df['date'].str[:6]).last()\n",
                "    bv_df = bv_df.drop(columns=['date', 'd_vol']).reset_index()\n",
                "    monthly_bv_list.append(bv_df)\n",
                "# Create monthly df\n",
                "bv_df = pd.concat(monthly_bv_list, ignore_index=True)\n",
                "# Create daily df\n",
                "daily_bv_df = pd.concat(daily_bv_list, ignore_index=True)\n",
                "# Use 138812 for equation 3\n",
                "bv_df = bv_df.loc[(bv_df['date'] >= '138812') & (bv_df['date'] <= '139900')]\n",
                "bv_df.reset_index(drop=True, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read rahavard 365 data for calculating returns\n",
                "# Concat all 75 tickers' data\n",
                "daily_list = []\n",
                "monthly_list = []\n",
                "for file_number in range(1, 76):\n",
                "    rahavard_path = f'E:/Thesis/New Sampling/Daily Data - Rahavard 365/'\\\n",
                "        f'{file_number}.txt'\n",
                "    df = pd.read_csv(\n",
                "        rahavard_path,\n",
                "        usecols=[2, 7],\n",
                "        names=['date', 'adj_close'],\n",
                "        header=0,\n",
                "        dtype={'date': str},\n",
                "        parse_dates=[0]\n",
                "    )\n",
                "    # Solve index reading problem, pandas add 2 index to the df\n",
                "    df.reset_index(drop=True, inplace=True)\n",
                "    # Convert to shamsi dates\n",
                "    df['date'] = df['date'].apply(\n",
                "        lambda x: jdatetime.date.fromgregorian(date=x).strftime('%Y%m%d')\n",
                "    )\n",
                "    df.insert(1, 'ticker_num', file_number)\n",
                "    df['i_return'] = df['adj_close'].pct_change()\n",
                "    daily_list.append(df)\n",
                "    # Create monthly dataframe\n",
                "    monthly_df = df.groupby(df['date'].str[:6]).last()\n",
                "    monthly_df = monthly_df.drop(columns=['date']).reset_index()\n",
                "    monthly_df['monthly_return'] = monthly_df['adj_close'].pct_change()\n",
                "    monthly_df.drop(columns=['i_return'], inplace=True)\n",
                "    monthly_list.append(monthly_df)\n",
                "# Create Monthly df for caculating fama-french factors\n",
                "monthly_df = pd.concat(monthly_list, ignore_index=True)\n",
                "monthly_df = monthly_df.loc[(\n",
                "    monthly_df['date'] >= '138900') & (monthly_df['date'] <= '139900')\n",
                "]\n",
                "monthly_df.dropna(inplace=True)\n",
                "monthly_df.reset_index(drop=True, inplace=True)\n",
                "# Create daily df for calculating PS factor\n",
                "df = pd.concat(daily_list, ignore_index=True)\n",
                "df.dropna(inplace=True)\n",
                "df.reset_index(drop=True, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add d_vol to df from bourseview Since rahavard 365 doesn't have such a data\n",
                "daily_df = pd.merge(df, daily_bv_df, on=['ticker_num', 'date'])\n",
                "daily_df.drop(columns=['market_cap'], inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Merge market cap and price dfs\n",
                "monthly_merged_df = pd.merge(monthly_df, bv_df, on=['ticker_num', 'date'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract all months from index df\n",
                "index_path = r'E:\\Thesis\\New Sampling\\TEDPIX\\شاخص كل6.xls'\n",
                "index_df = pd.read_excel(\n",
                "    index_path,\n",
                "    usecols=[1, 3],\n",
                "    names=['date', 'close'],\n",
                "    dtype={'date': str}\n",
                ")\n",
                "index_df.dropna(inplace=True)\n",
                "index_df['m_return'] = index_df['close'].pct_change()\n",
                "all_months = pd.Series(index_df['date'].str[:6].unique().tolist())\n",
                "all_months.name = 'date'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create target years list\n",
                "years_list = me_df.columns[2:].tolist()[::-1]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Calculating MKT, SMB, and HML"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculating SMB and HML\n",
                "smb_list = []\n",
                "hml_list = []\n",
                "for year in years_list:\n",
                "    # Select specific year\n",
                "    # Eliminate negative BM tickers or NaN tickers for that year\n",
                "    applicable_tickers = bm_df.loc[bm_df[year] >= 0]['ticker_num'].tolist()\n",
                "    negative_be_condition = me_df['ticker_num'].isin(applicable_tickers)\n",
                "    temp_me = me_df.loc[negative_be_condition][['ticker_num', 'ticker', year]]\n",
                "    temp_bm = bm_df.loc[negative_be_condition][['ticker_num', 'ticker', year]]\n",
                "    # Split each year ME into two groups\n",
                "    conditions = [\n",
                "        (temp_me[year] > temp_me[year].median()),\n",
                "        (temp_me[year] <= temp_me[year].median())\n",
                "    ]\n",
                "    temp_bm['size'] = np.select(conditions, ['B', 'S']).tolist()\n",
                "    # Split each ME group into three B/M groups\n",
                "    q = [0, .3, .7, 1]\n",
                "    labels = ['L', 'M', 'H']\n",
                "    x_b = temp_bm.loc[temp_bm['size'] == 'B'][year]\n",
                "    b_bm = pd.qcut(x=x_b, q=q, labels=labels).to_dict()\n",
                "    x_s = temp_bm.loc[temp_bm['size'] == 'S'][year]\n",
                "    s_bm = pd.qcut(x=x_s, q=q, labels=labels).to_dict()\n",
                "    temp_bm['bm'] = pd.Series(b_bm)\n",
                "    temp_bm['bm'].update(pd.Series(s_bm))\n",
                "    # Extrect six portfolio ticker numbers\n",
                "    temp_bm['res'] = temp_bm['size'] + temp_bm['bm']\n",
                "    bh = temp_bm.loc[temp_bm['res'] == 'BH']['ticker_num'].tolist()\n",
                "    bm = temp_bm.loc[temp_bm['res'] == 'BM']['ticker_num'].tolist()\n",
                "    bl = temp_bm.loc[temp_bm['res'] == 'BL']['ticker_num'].tolist()\n",
                "    sh = temp_bm.loc[temp_bm['res'] == 'SH']['ticker_num'].tolist()\n",
                "    sm = temp_bm.loc[temp_bm['res'] == 'SM']['ticker_num'].tolist()\n",
                "    sl = temp_bm.loc[temp_bm['res'] == 'SL']['ticker_num'].tolist()\n",
                "    next_year = str(1 + int(year))\n",
                "    next_year_months = all_months[all_months.str[2:4] == next_year]\n",
                "    for month in next_year_months:\n",
                "        # Set conditions\n",
                "        month_condition = (monthly_merged_df['date'] == month)\n",
                "        bh_condition = monthly_merged_df['ticker_num'].isin(bh)\n",
                "        bm_condition = monthly_merged_df['ticker_num'].isin(bm)\n",
                "        bl_condition = monthly_merged_df['ticker_num'].isin(bl)\n",
                "        sh_condition = monthly_merged_df['ticker_num'].isin(sh)\n",
                "        sm_condition = monthly_merged_df['ticker_num'].isin(sm)\n",
                "        sl_condition = monthly_merged_df['ticker_num'].isin(sl)\n",
                "        # Construct portfolios\n",
                "        bh_portfolio = monthly_merged_df.loc[month_condition & bh_condition]\n",
                "        bm_portfolio = monthly_merged_df.loc[month_condition & bm_condition]\n",
                "        bl_portfolio = monthly_merged_df.loc[month_condition & bl_condition]\n",
                "        sh_portfolio = monthly_merged_df.loc[month_condition & sh_condition]\n",
                "        sm_portfolio = monthly_merged_df.loc[month_condition & sm_condition]\n",
                "        sl_portfolio = monthly_merged_df.loc[month_condition & sl_condition]\n",
                "        # Calculate value-weighted returns\n",
                "        bh_return = np.average(\n",
                "            bh_portfolio.monthly_return,\n",
                "            weights=bh_portfolio.market_cap\n",
                "        )\n",
                "        bm_return = np.average(\n",
                "            bm_portfolio.monthly_return,\n",
                "            weights=bm_portfolio.market_cap\n",
                "        )\n",
                "        bl_return = np.average(\n",
                "            bl_portfolio.monthly_return,\n",
                "            weights=bl_portfolio.market_cap\n",
                "        )\n",
                "        sh_return = np.average(\n",
                "            sh_portfolio.monthly_return,\n",
                "            weights=sh_portfolio.market_cap\n",
                "        )\n",
                "        sm_return = np.average(\n",
                "            sm_portfolio.monthly_return,\n",
                "            weights=sm_portfolio.market_cap\n",
                "        )\n",
                "        sl_return = np.average(\n",
                "            sl_portfolio.monthly_return,\n",
                "            weights=sl_portfolio.market_cap\n",
                "        )\n",
                "        # Calculate SMB and HML. Then, add them to lists\n",
                "        smb = (\n",
                "            ((sh_return + sm_return + sl_return) / 3)\n",
                "            - ((bh_return + bm_return + bl_return) / 3)\n",
                "        )\n",
                "        smb_list.append(smb)\n",
                "        hml = (\n",
                "            ((sh_return + bh_return) / 2)\n",
                "            - ((sl_return + bl_return) / 2)\n",
                "        )\n",
                "        hml_list.append(hml)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create df from calculated SMB and HML, and write it to excel\n",
                "ff_df = pd.DataFrame([smb_list, hml_list]).transpose()\n",
                "ff_df.to_excel('smb_hml_for_ps.xlsx', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculating MKT\n",
                "# Calculate index monthly return\n",
                "index_path = r'E:\\Thesis\\New Sampling\\TEDPIX\\شاخص كل6.xls'\n",
                "index_df = pd.read_excel(\n",
                "    index_path,\n",
                "    usecols=[1, 3],\n",
                "    names=['date', 'close'],\n",
                "    dtype={'date': str}\n",
                ")\n",
                "index_df.dropna(inplace=True)\n",
                "labels = index_df['date'].str[:6]\n",
                "index_monthly_df = index_df.groupby(labels)[['close']].last().reset_index()\n",
                "index_monthly_df['m_return'] = index_monthly_df['close'].pct_change()\n",
                "# Calculate monthly risk free rate\n",
                "rf_path = r'C:\\Users\\behnood\\Desktop\\Thesis\\TSETMC'\\\n",
                "    r'\\Risk Free Rate\\monthly_rf_ps.xlsx'\n",
                "rf_df = pd.read_excel(\n",
                "    rf_path,\n",
                "    usecols=[0, 2],\n",
                "    names=['date', 'rf_return'],\n",
                "    dtype={'date': str}\n",
                ")\n",
                "# Calculate MKT and write to excel\n",
                "mkt_df = pd.merge(index_monthly_df, rf_df, on='date')\n",
                "mkt_df['mkt'] = mkt_df['m_return'] - mkt_df['rf_return']\n",
                "mkt_df.to_excel('mkt_for_PS.xlsx', index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Calculating LIQ"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Equation 1: Liquidity Calculation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<center>\n",
                "    <img src=\"https://docs.google.com/uc?export=download&id=1DsiUSR-yoJ3TLLuisiKnU5dZRnYtlQmY\" width=\"500\" height=\"50\"/>\n",
                "</center>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "merged_df = pd.merge(daily_df, index_df, on='date').dropna().reset_index(drop=True)\n",
                "merged_df.sort_values(['ticker_num', 'date'], inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "liq_list = []\n",
                "for file_number in range(1, 76):\n",
                "    print(file_number)\n",
                "    ticker_condition = (merged_df['ticker_num'] == file_number)\n",
                "    months = pd.Series(merged_df[ticker_condition]['date'].str[:6].unique())\n",
                "    months = months[(months >= '138900') & (months <= '139800')].tolist()\n",
                "    for month in months:\n",
                "        month_condition = merged_df['date'].str.startswith(month)\n",
                "        liq_reg_df = merged_df.loc[ticker_condition & month_condition]\n",
                "        counted_days = liq_reg_df.loc[month_condition]['date'].count()\n",
                "        # Check for 15 days condition\n",
                "        if counted_days >= 15:\n",
                "            liq_reg_df['r_diff'] = (\n",
                "                liq_reg_df['i_return']\n",
                "                - liq_reg_df['m_return']\n",
                "            )\n",
                "            liq_reg_df['r_diff (d+1)'] = liq_reg_df['r_diff'].shift(-1)\n",
                "            liq_reg_df['sign(r_diff).vol'] = (\n",
                "                liq_reg_df['d_vol']\n",
                "                * np.sign(liq_reg_df['r_diff'])\n",
                "            )\n",
                "            liq_reg_df.dropna(inplace=True)\n",
                "            # Estimate regression\n",
                "            y = liq_reg_df['r_diff (d+1)']\n",
                "            x = liq_reg_df[['i_return', 'sign(r_diff).vol']]\n",
                "            model = LinearRegression()\n",
                "            model.fit(x, y)\n",
                "            liq = model.coef_[1]\n",
                "            liq_list.append([month, file_number, liq])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "liq_df = pd.DataFrame(liq_list, columns=['date', 'ticker_num', 'liq'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Equation 2: Aggregate Liquidity Calculation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<center>\n",
                "    <img src=\"https://docs.google.com/uc?export=download&id=1vQWTanYX_Ezn520I9TlLB7AsLZ6GlCf-\" width=\"300\" height=\"100\"/>\n",
                "</center>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Equation 3: Innovations to Aggregate Liquidity Calculation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<center>\n",
                "    <img src=\"https://docs.google.com/uc?export=download&id=1iFL-bC2e1G3lKjt2Q2ehOLyhqjk6PtGm\" width=\"300\" height=\"100\">\n",
                "</center>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<center>\n",
                "    <img src=\"https://docs.google.com/uc?export=download&id=1m3irjSVqV0XgNw5R1t_aQbfyvoSkHdm7\" width=\"300\" height=\"100\"/>\n",
                "</center>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "months = liq_df['date'].unique().tolist()\n",
                "months.sort()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "eqq_3_list = []\n",
                "for idx, month in enumerate(months):\n",
                "    all_months_list = all_months.tolist()\n",
                "    previous_month = all_months_list[all_months_list.index(month) - 1]\n",
                "    if idx == 0:\n",
                "        # M is the market capitalization of eligible stocks\n",
                "        # at the end of month t −1\n",
                "        # Calculate first M\n",
                "        cur_month_condition = (liq_df['date'] == month)\n",
                "        current_elig = liq_df.loc[cur_month_condition]['ticker_num'].tolist()\n",
                "        month_condition = (bv_df['date'] == previous_month)\n",
                "        ticker_condition = bv_df['ticker_num'].isin(current_elig)\n",
                "        first_m = bv_df.loc[\n",
                "            month_condition & ticker_condition\n",
                "        ]['market_cap'].sum()\n",
                "    if idx >= 1:\n",
                "        # A list of eligible tickers in current month\n",
                "        cur_month_condition = (liq_df['date'] == month)\n",
                "        current_elig = liq_df.loc[cur_month_condition]['ticker_num'].tolist()\n",
                "        # A list of eligible tickers in previous month\n",
                "        prev_month_condition = (liq_df['date'] == previous_month)\n",
                "        previous_elig = liq_df.loc[prev_month_condition]['ticker_num'].tolist()\n",
                "        # Calculate M\n",
                "        month_condition = (bv_df['date'] == previous_month)\n",
                "        ticker_condition = bv_df['ticker_num'].isin(previous_elig)\n",
                "        m = bv_df.loc[month_condition & ticker_condition]['market_cap'].sum()\n",
                "        # Calculate N\n",
                "        # The number of tickers that are eligible in both\n",
                "        # current and previous months\n",
                "        n = len(list(set(current_elig).intersection(previous_elig)))\n",
                "        # A list of tickers that are eligible in both\n",
                "        # current and previous months\n",
                "        both_elig = list(set(current_elig).intersection(previous_elig))\n",
                "        both_elig_condition = liq_df['ticker_num'].isin(both_elig)\n",
                "        cur_elig_condition = liq_df['ticker_num'].isin(current_elig)\n",
                "        prev_elig_condition = liq_df['ticker_num'].isin(previous_elig)\n",
                "        # Calculate agg lig for month t\n",
                "        prev_agg_liq = liq_df.loc[\n",
                "            cur_elig_condition & prev_month_condition\n",
                "        ]['liq'].sum()\n",
                "        # Calculate delta agg liq (innov)\n",
                "        scaled_cur_agg_liq = liq_df.loc[\n",
                "            both_elig_condition & cur_month_condition\n",
                "        ]['liq'].sum()\n",
                "        scaled_prev_agg_liq = liq_df.loc[\n",
                "            both_elig_condition & prev_month_condition\n",
                "        ]['liq'].sum()\n",
                "        innov =(\n",
                "            (m / first_m)\n",
                "            * (1 / n)\n",
                "            * (scaled_cur_agg_liq - scaled_prev_agg_liq)\n",
                "        )\n",
                "        eqq_3_list.append([month, m, n, prev_agg_liq, innov])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "inv_df = pd.DataFrame(\n",
                "    eqq_3_list,\n",
                "    columns=['date', 'm', 'n', 'prev_agg_liq', 'innov']\n",
                ")\n",
                "inv_df['m (t-1)'] = inv_df['m'].shift()\n",
                "inv_df['innov (t-1)'] = inv_df['innov'].shift()\n",
                "inv_df.dropna(inplace=True)\n",
                "inv_df.reset_index(drop=True, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ff_path = r'C:\\Users\\behnood\\Desktop\\Thesis\\TSETMC\\Factor Model'\\\n",
                "r'\\Pastor Stambaugh\\FF_for_PS.xlsx'\n",
                "ff_df = pd.read_excel(ff_path, dtype={'date': str})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate tickers excess return\n",
                "new_monthly_df = pd.merge(monthly_df, rf_df, on='date')\n",
                "new_monthly_df['excess_return'] = (\n",
                "    new_monthly_df['monthly_return'] - new_monthly_df['rf_return']\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_years = [\n",
                "    '1389', '1390', '1391', '1392', '1393',\n",
                "    '1394', '1395', '1396', '1397', '1398'\n",
                "]\n",
                "target_years = ['1394', '1395', '1396', '1397', '1398']\n",
                "liq_betas = []\n",
                "for year in target_years:\n",
                "    five_years_ago = all_years[:all_years.index(year)][-5]\n",
                "    end_point = f'{year}00'\n",
                "    start_point = f'{five_years_ago}00'\n",
                "    selected_period = inv_df.loc[\n",
                "        (inv_df['date'] >= start_point)\n",
                "        & (inv_df['date'] <= end_point)\n",
                "    ]\n",
                "    selected_period['(mt-1/mt).innov(t-1)'] = (\n",
                "        selected_period['m (t-1)']\n",
                "        / selected_period['m']\n",
                "        * selected_period['innov (t-1)']\n",
                "    )\n",
                "    y = selected_period['innov']\n",
                "    x = selected_period[['innov (t-1)', '(mt-1/mt).innov(t-1)']]\n",
                "    model = LinearRegression()\n",
                "    model.fit(x, y)\n",
                "    prediction = model.predict(x)\n",
                "    residuals = (y - prediction)\n",
                "    gammas = residuals/100\n",
                "    selected_ff = ff_df.loc[\n",
                "        (ff_df['date'] >= start_point)\n",
                "        & (ff_df['date'] <= end_point)\n",
                "    ]\n",
                "    selected_ff.insert(1, 'L', gammas)\n",
                "    full_five_years = selected_ff.shape[0]\n",
                "    for ticker_number in range(1, 76):\n",
                "        excess_returns = new_monthly_df.loc[\n",
                "            (new_monthly_df['ticker_num'] == ticker_number)\n",
                "            & (new_monthly_df['date'] >= selected_ff['date'].tolist()[0])\n",
                "            & (new_monthly_df['date'] <= selected_ff['date'].tolist()[-1])\n",
                "        ]['excess_return'].tolist()\n",
                "        ticker_months_count = len(excess_returns)\n",
                "        if ticker_months_count == full_five_years:\n",
                "            temp_selected_ff = selected_ff.copy()\n",
                "            temp_selected_ff.insert(1, 'excess_return', excess_returns)\n",
                "            y = temp_selected_ff['excess_return']\n",
                "            x = temp_selected_ff[['L', 'mkt', 'smb', 'hml']]\n",
                "            model = LinearRegression()\n",
                "            model.fit(x, y)\n",
                "            ticker_liq_beta = model.coef_[0]\n",
                "            liq_betas.append([year, ticker_number, ticker_liq_beta])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "beta_df = pd.DataFrame(liq_betas, columns=['year', 'ticker_num', 'beta'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Equation 4: Tradable Liquidity Risk Factor"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<center>\n",
                "    <img src=\"https://docs.google.com/uc?export=download&id=1dPPrNJnL9D_VMAWyi2c1P0lOwvyuUZWO\" width=\"500\" height=\"50\"/>\n",
                "</center>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_list = []\n",
                "for year in beta_df['year'].unique().tolist():\n",
                "    selected_year = beta_df.loc[beta_df['year'] == year]\n",
                "    beta_deciles = pd.qcut(\n",
                "        selected_year['beta'],\n",
                "        q=10,\n",
                "        labels=list(range(1, 11)[::-1])\n",
                "    ).to_dict()\n",
                "    selected_year['decile'] = pd.Series(beta_deciles)\n",
                "    decile_1 = selected_year.loc[\n",
                "        selected_year['decile'] == 1\n",
                "    ]['ticker_num'].tolist()\n",
                "    decile_10 = selected_year.loc[\n",
                "        selected_year['decile'] == 10\n",
                "    ]['ticker_num'].tolist()\n",
                "    twelve_months = index_monthly_df.loc[\n",
                "        index_monthly_df['date'].str.startswith(year)\n",
                "    ]['date'].tolist()\n",
                "    for month in twelve_months:\n",
                "        decile_1_condition = monthly_merged_df['ticker_num'].isin(decile_1)\n",
                "        decile_10_condition = monthly_merged_df['ticker_num'].isin(decile_10)\n",
                "        month_condition = (monthly_merged_df['date'] == month)\n",
                "        decile_1_portfolio = monthly_merged_df.loc[\n",
                "            decile_1_condition & month_condition\n",
                "        ]\n",
                "        decile_10_portfolio = monthly_merged_df.loc[\n",
                "            decile_10_condition & month_condition\n",
                "        ]\n",
                "        # Calculate value-weighted returns\n",
                "        decile_1_return = np.average(\n",
                "            decile_1_portfolio.monthly_return,\n",
                "            weights=decile_1_portfolio.market_cap\n",
                "        )\n",
                "        decile_10_return = np.average(\n",
                "            decile_10_portfolio.monthly_return,\n",
                "            weights=decile_10_portfolio.market_cap\n",
                "        )\n",
                "        liq = decile_10_return - decile_1_return\n",
                "        final_list.append(liq)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Write calculate liq factor to excel\n",
                "ps_df = pd.DataFrame(final_list, columns=['LIQ'])\n",
                "ps_df.to_excel('PS_factor_2.xlsx', index=False)"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "cb65928c389f17aa552142cf7c412739256798faf8dbcb7a69e391c3cff383e3"
        },
        "kernelspec": {
            "display_name": "Python 3.7.5 64-bit",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.5"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
